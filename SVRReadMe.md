# ImplementaciÃ³n de algoritmo de submuestreo para Support Vector Regression en conjuntos de grandes volÃºmenes de datosâ€‹

_Estaba pensando en poner algo del abstract o de la introducciÃ³n de tu texto_

## Contenido del repositorio ğŸ“Œ

_El proyecto estÃ¡ compuesto por los notebooks en los que se realizÃ³ la aplicaciÃ³n del algoritmo de submuestreo, el cual se encuentra definido en un archivo _**.py**_. Detalladamente, cada uno se enfoca en un conjunto de dato especÃ­ficos que se describen de la siguiente manera:_

- El conjuto de datos _Temp Electric Motor_ es un archivo csv que comprende varios datos de sensores recopilados de un motor sÃ­ncrono de imanes permanentes (PMSM). Las caracterÃ­sticas objetivo mÃ¡s interesantes son la temperatura del rotor ("pm"), las temperaturas del estator ("stator_*") y el par.
    Tomado de: <https://www.kaggle.com/wkirgsn/electric-motor-temperature>
- El conjuto de datos _UK Used Car_ contiene 100.000 listados de autos usados y cada columna representa la informaciÃ³n de precio, transmisiÃ³n, kilometraje, tipo de combustible, impuesto de circulaciÃ³n, millas por galÃ³n (mpg) y tamaÃ±o del motor. La variable objetivo es el precio de venta del automÃ³vil, para predecirlo a partir de sus caracterÃ­sticas.
    Tomado de: <https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes>
- El conjuto de datos _Beijing PM 2.5_ tiene como variable objetivo la partÃ­cula contaminante PM 2.5 que se encuentra en el aire. EstÃ¡ compuesto por los datos de PM2.5 de la Embajada de EE. UU. En Beijing por hora.
    Tomado de: <https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data>
    

### Pre-requisitos ğŸ”§

_Inicialmente, para realizar alguna aplicaciÃ³n del algoritmo de submuestreo es importante confirmar que se podrÃ¡n importar adecuadamente las siguientes librerias en Python: pandas, sklearn, time, math, from skopt: BayesSearchCV._
_Para importar el archivo **.py** y hacer uso del algoritmo, se debe definir los parÃ¡metros que recibe: 
```
svr_subsample_bayes_train(trainD,testD,sig,ep,y_label_name,kernel_type,num_neighbors,thres,rs=45)
```

|  ParÃ¡metros      | DescripciÃ³n de parÃ¡metro |
| -----------------|:-------------:|
| **trainD**       | Train data     |
| **testD**        | Test data     |
| **sig**          | Percentage of the subsampleT (0.01 or  0.1)   |
| **ep**           | Percentage of R set (usually 0.1)    |
| **y_label_name** | Column name of the target variable     |
| **kernel_type**  | Type of kernel ('linear', 'poly', 'rbf')   |
| **num_neighbors**| Number of neighbors to look for (5 when sig=0.01 or 3 when sig=0.1)     |
| **thres**        | Threshold for the callback function on_step     |
| **rs**           | random_state seed for the reproducibility of the experiment   |

## DescripciÃ³n del algoritmo de submuestreo ğŸ› ï¸

La implementaciÃ³n del algoritmo tiene como base _Nearest neighbors methods for support vector machines, Camelo, S. A.,GonzÃ¡lez-Lima, M. D.,Quiroz, A. J. Adapted for SVR._ Teniendo en cuenta los siguientes pasos, que dependiendo de los resultados obtenidos puede requerir mÃ¡s de una iteraciÃ³n:

1. En la primera iteraciÃ³n, selecciona una submuestra aleatoria ğ‘»(ğŸ) de tamaÃ±o Î´n del conjunto de datos de entrenamiento elegido de tamaÃ±o n, que en este caso serÃ¡ llamado D.
```
submuestraT = trainD.sample (frac = sig, random_state = rs)
```
2. Inicializa un nuevo conjunto ğ‘º(ğŸ) que sea la diferencia entre D y ğ‘»(ğŸ)

```
submuestra_index = lista (submuestraT.index)
SetS = trainD.drop (subsample_index, eje = 0)
```
3. Resolver el problema de RVS para ğ‘»(ğŸ) e identifique los vectores de soporte ğ‘ºğ‘½(0)
> En este paso, se aplica la optomizaciÃ³n bayesiana para la optimizaciÃ³n de hiperparÃ¡metros. 
> Si es una nueva iteraciÃ³n, se realiza la intersecciÃ³n del anterior ğ‘¹(ğ’‹ âˆ’ ğŸ) con el actual ğ‘ºğ‘½(ğ’‹)
4. Definir un nuevo conjunto ğ‘µ(ğ’‹) encontrando los k vecinos mÃ¡s cercanos en ğ‘º(j) para cada Support Vector.
5. Crear un nuevo conjunto ğ‘¹(ğ’‹) dejando caer todos los N ubicados en ğ‘º(ğ’‹).
6. Unifica ğ‘¹(ğ’‹), ğ‘µ(ğ’‹) y ğ‘ºğ‘½ (ğ’‹) en un solo conjunto llamado ğ‘»(ğ’‹ + ğŸ).
7. Resuelva el problema de SVR para ğ‘»(ğ’‹ + ğŸ).
> Adicionalmente, se define ğ‘º (ğ’‹ + ğŸ) que es el actual ğ‘º(ğ’‹) menos (ğ’ğ•âˆªğ‘¹).
8. Si no hay una mejora significativa del error de regresiÃ³n, regrese al paso 3.
> En la nueva iteraciÃ³n: ğ’‹ â† ğ’‹+ğŸ 

## BibliografÃ­a ğŸ“–

_Nearest neighbors methods for support vector machines, Camelo, S. A.,GonzÃ¡lez-Lima, M. D.,Quiroz, A. J._


## Expresiones de Gratitud ğŸ

* Gracias...



---
Proyecto por [jsvillatech](https://github.com/jsvillatech)
