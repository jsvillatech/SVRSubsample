# Implementaci√≥n de algoritmo de submuestreo para Support Vector Regression en conjuntos de grandes vol√∫menes de datos‚Äã

_Las m√°quinas de vectores de soporte son un algoritmo de aprendizaje supervisado para la clasificaci√≥n y la regresi√≥n introducido por Vladimir Vapnik y otros en los a√±os 60. Este algoritmo ha mostrado resultados impresionantes cuando se trata de clasificar o predecir datos lineales y no lineales gracias a las funciones kernel que le ayudan a generalizar datos m√°s complejos. A pesar de los impresionantes resultados, este algoritmo no es adecuado para grandes conjuntos de datos porque se vuelve inmanejable desde el punto de vista computacional y requiere demasiado tiempo de entrenamiento. Proponemos una implementaci√≥n extendida y novedosa de un algoritmo de submuestra propuesto por (1) enfocado en regresi√≥n de vectores de soporte (SVR) y utilizando el lenguaje de programaci√≥n Python junto con optimizaci√≥n de hiperpar√°metros. Comparamos diferentes m√©tricas como RMSE, MAE, $R^2$ y obtuvimos resultados interesantes, haciendo que nuestra propuesta de implementaci√≥n sea hasta 20,8 veces m√°s r√°pida que el algoritmo SVR solo._


## Contenido del repositorio üìå

_El proyecto est√° compuesto por los notebooks en los que se realiz√≥ la aplicaci√≥n del algoritmo de submuestreo, el cual se encuentra definido en un archivo _**.py**_. Detalladamente, cada uno se enfoca en un conjunto de datos espec√≠ficos que se describen de la siguiente manera:_

- El conjuto de datos _Temp Electric Motor_ es un archivo csv que comprende varios datos de sensores recopilados de un motor s√≠ncrono de imanes permanentes (PMSM). Las caracter√≠sticas objetivo m√°s interesantes son la temperatura del rotor ("pm"), las temperaturas del estator ("stator_*") y el par.
    Tomado de: <https://www.kaggle.com/wkirgsn/electric-motor-temperature>
- El conjuto de datos _UK Used Car_ contiene 100.000 listados de autos usados y cada columna representa la informaci√≥n de precio, transmisi√≥n, kilometraje, tipo de combustible, impuesto de circulaci√≥n, millas por gal√≥n (mpg) y tama√±o del motor. La variable objetivo es el precio de venta del autom√≥vil, para predecirlo a partir de sus caracter√≠sticas.
    Tomado de: <https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes>
- El conjuto de datos _Beijing PM 2.5_ tiene como variable objetivo la part√≠cula contaminante PM 2.5 que se encuentra en el aire. Est√° compuesto por los datos de PM2.5 de la Embajada de EE. UU. En Beijing por hora.
    Tomado de: <https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data>
    

### Pre-requisitos üîß

_Inicialmente, para realizar alguna aplicaci√≥n del algoritmo de submuestreo es importante confirmar que se podr√°n importar adecuadamente las siguientes librerias en Python: pandas, sklearn, time, math, from skopt: BayesSearchCV._
_Para importar el archivo **.py** y hacer uso del algoritmo, se debe definir los par√°metros que recibe: 
```
svr_subsample_bayes_train(trainD,testD,sig,ep,y_label_name,kernel_type,num_neighbors,thres,rs=45)
```

|  Par√°metros      | Descripci√≥n de par√°metro |
| -----------------|:-------------:|
| **trainD**       | Train data     |
| **testD**        | Test data     |
| **sig**          | Percentage of the subsampleT (0.01 or  0.1)   |
| **ep**           | Percentage of R set (usually 0.1)    |
| **y_label_name** | Column name of the target variable     |
| **kernel_type**  | Type of kernel ('linear', 'poly', 'rbf')   |
| **num_neighbors**| Number of neighbors to look for (5 when sig=0.01 or 3 when sig=0.1)     |
| **thres**        | Threshold for the callback function on_step     |
| **rs**           | random_state seed for the reproducibility of the experiment   |

## Descripci√≥n del algoritmo de submuestreo üõ†Ô∏è

La implementaci√≥n del algoritmo tiene como base _Nearest neighbors methods for support vector machines, Camelo, S. A.,Gonz√°lez-Lima, M. D.,Quiroz, A. J. Adapted for SVR._ Teniendo en cuenta los siguientes pasos, que dependiendo de los resultados obtenidos puede requerir m√°s de una iteraci√≥n:

1. En la primera iteraci√≥n, selecciona una submuestra aleatoria ùëª(ùüé) de tama√±o Œ¥n del conjunto de datos de entrenamiento elegido de tama√±o n, que en este caso ser√° llamado D.
```
submuestraT = trainD.sample (frac = sig, random_state = rs)
```
2. Inicializa un nuevo conjunto ùë∫(ùüé) que sea la diferencia entre D y ùëª(ùüé)

```
submuestra_index = lista (submuestraT.index)
SetS = trainD.drop (subsample_index, eje = 0)
```
3. Resolver el problema de RVS para ùëª(ùüé) e identifique los vectores de soporte ùë∫ùëΩ(0)
> En este paso, se aplica la optomizaci√≥n bayesiana para la optimizaci√≥n de hiperpar√°metros. 
> Si es una nueva iteraci√≥n, se realiza la intersecci√≥n del anterior ùëπ(ùíã ‚àí ùüè) con el actual ùë∫ùëΩ(ùíã)
4. Definir un nuevo conjunto ùëµ(ùíã) encontrando los k vecinos m√°s cercanos en ùë∫(j) para cada Support Vector.
5. Crear un nuevo conjunto ùëπ(ùíã) dejando caer todos los N ubicados en ùë∫(ùíã).
6. Unifica ùëπ(ùíã), ùëµ(ùíã) y ùë∫ùëΩ (ùíã) en un solo conjunto llamado ùëª(ùíã + ùüè).
7. Resuelva el problema de SVR para ùëª(ùíã + ùüè).
> Adicionalmente, se define ùë∫ (ùíã + ùüè) que es el actual ùë∫(ùíã) menos (ùêíùêï‚à™ùëπ).
8. Si no hay una mejora significativa del error de regresi√≥n, regrese al paso 3.
> En la nueva iteraci√≥n: ùíã ‚Üê ùíã+ùüè 

## Bibliograf√≠a üìñ

_(1)Nearest neighbors methods for support vector machines, Camelo, S. A.,Gonz√°lez-Lima, M. D.,Quiroz, A. J._


## Expresiones de Gratitud üéÅ

* A los profes An√≠bal Sosa y Mar√≠a de los √Ångeles Lima por todo su apoyo y gu√≠a durante el proyecto.
* A la universidad Icesi, y los profes por toda la experiencia y ense√±anzas durante el programa.
* A mi compa√±era y amiga Ana Mu√±oz por su colaboraci√≥n y entusiasmo por el aprendizaje.



---
Proyecto por [jsvillatech](https://github.com/jsvillatech)
